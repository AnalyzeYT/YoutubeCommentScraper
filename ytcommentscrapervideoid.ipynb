{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9051373,"sourceType":"datasetVersion","datasetId":5416683}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"MyAPI = 'Replace Youtube API Key'\nMyID = \"Replace with youtube video URL\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prompt: write a program to extract these informations \"VideoID\tChannel\tNumOfCommentlikes\tNumOfCommentDislikes\tNumOfReplies\tComment\tCommentedUserID\tRepliedUserID\tReply\tRepliesLikes\tRepliesDislike\tToWhomTheyReplied\tComment|repliedTime\tVideoUploadedtimeanddate\" using youtube api and save the file as csv file as videoid as file name.\n\nfrom googleapiclient.discovery import build\nimport csv\n#import isodate\n\n# Replace with your API key and video ID\n#MyAPI = 'YOUR_API_KEY' \n#MyID = 'YOUR_VIDEO_ID' \n\n!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\napi_key = MyAPI\nyoutube = build('youtube', 'v3', developerKey=api_key)\n\ndef get_video_details(video_id, api_key):\n  request = youtube.videos().list(\n      part=\"snippet,statistics\",\n      id=video_id\n  )\n  response = request.execute()\n  return response['items'][0]\n\ndef get_comments(video_id, api_key):\n  comments = []\n\n  request = youtube.commentThreads().list(\n      part=\"snippet,replies\",\n      videoId=video_id,\n      textFormat=\"plainText\"\n  )\n\n  while request:\n    response = request.execute()\n\n    for item in response['items']:\n      comment = item['snippet']['topLevelComment']['snippet']\n      comment_data = {\n          'VideoID': video_id,\n          'Channel': comment['authorDisplayName'],\n          'NumOfCommentlikes': comment['likeCount'],\n          'NumOfCommentDislikes': comment.get('dislikeCount', 0), # Dislikes are not available anymore\n          'Comment': comment['textDisplay'],\n          'CommentedUserID': comment['authorChannelUrl'],\n          'Comment|repliedTime': comment['publishedAt'], \n      }\n\n      if 'replies' in item:\n        for reply in item['replies']['comments']:\n          reply_snippet = reply['snippet']\n          comment_data['NumOfReplies'] = len(item['replies']['comments'])\n          comment_data['RepliedUserID'] = reply_snippet['authorChannelUrl']\n          comment_data['Reply'] = reply_snippet['textDisplay']\n          comment_data['RepliesLikes'] = reply_snippet['likeCount']\n          comment_data['RepliesDislike'] = reply_snippet.get('dislikeCount', 0) # Dislikes are not available anymore\n          comment_data['ToWhomTheyReplied'] = comment['authorDisplayName']\n          comments.append(comment_data.copy())\n      else:\n        comment_data['NumOfReplies'] = 0\n        comment_data['RepliedUserID'] = ''\n        comment_data['Reply'] = ''\n        comment_data['RepliesLikes'] = 0\n        comment_data['RepliesDislike'] = 0\n        comment_data['ToWhomTheyReplied'] = ''\n        comments.append(comment_data.copy())\n\n    request = youtube.commentThreads().list_next(request, response)\n\n  return comments\n\nvideo_details = get_video_details(MyID, api_key)\ncomments = get_comments(MyID, api_key)\n\n# Get video upload time and date\nvideo_upload_time = video_details['snippet']['publishedAt']\n\n# Add video upload time to each comment\nfor comment in comments:\n  comment['VideoUploadedtimeanddate'] = video_upload_time\n\nfilename = f\"{MyID}.csv\"\nwith open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n  fieldnames = ['VideoID', 'Channel', 'NumOfCommentlikes', 'NumOfCommentDislikes', 'NumOfReplies', 'Comment', 'CommentedUserID', 'RepliedUserID', 'Reply', 'RepliesLikes', 'RepliesDislike', 'ToWhomTheyReplied', 'Comment|repliedTime', 'VideoUploadedtimeanddate'] \n  writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n  writer.writeheader()\n  for comment in comments:\n    writer.writerow(comment)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Multiple Comments download from ChannelID ","metadata":{}},{"cell_type":"code","source":"# prompt: write a code to extract these information from \"videoId,title, publishedAt, description, channelTitle, tags, duration, viewCount, likeCount, favoriteCount, TotalVideoCommentsCount, videoId, Channel, NumOfCommentlikes, NumOfReplies, Comment, CommentedUserID, RepliedUserID, Reply, RepliesLikes, ToWhomTheyReplied\" using youtube api and save the file as csv file as videoid as file name. Also for future use case check that csv file is existed or not if not create file and save else check the data is presented or not, if TotalVideoCommentsCount is equal to number of comments extracted from the same video then go to next videoId until fill complete information.\n\n!pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib\n\nfrom googleapiclient.discovery import build\nimport csv\nimport os\n\n# Set up the YouTube Data API v3 service\nAPI_KEY = 'A********************-****************E'  # Replace with your actual API key\nyoutube = build('youtube', 'v3', developerKey=API_KEY)\n\ndef get_channel_videos(channel_id):\n    \"\"\"Retrieve all video IDs from a given channel.\"\"\"\n    video_ids = []\n    next_page_token = None\n\n    while True:\n        request = youtube.search().list(\n            part=\"id\",\n            channelId=channel_id,\n            maxResults=50,\n            pageToken=next_page_token,\n            type=\"video\"\n        )\n        response = request.execute()\n\n        video_ids.extend([item['id']['videoId'] for item in response['items']])\n\n        next_page_token = response.get('nextPageToken')\n        if not next_page_token:\n            break\n\n    return video_ids\n\ndef get_video_details(video_id):\n    \"\"\"Retrieve video details and comments using the YouTube Data API.\"\"\"\n    video_response = youtube.videos().list(\n        part='snippet,contentDetails,statistics',\n        id=video_id\n    ).execute()\n\n    video_details = {}\n    comments_data = []\n    if 'items' in video_response and video_response['items']:\n        item = video_response['items'][0]\n        snippet = item['snippet']\n        statistics = item['statistics']\n        content_details = item['contentDetails']\n\n        video_details['videoId'] = video_id\n        video_details['title'] = snippet.get('title', '')\n        video_details['publishedAt'] = snippet.get('publishedAt', '')\n        video_details['description'] = snippet.get('description', '')\n        video_details['channelTitle'] = snippet.get('channelTitle', '')\n        video_details['tags'] = ','.join(snippet.get('tags', []))\n        video_details['duration'] = content_details.get('duration', '')\n        video_details['viewCount'] = statistics.get('viewCount', 0)\n        video_details['likeCount'] = statistics.get('likeCount', 0)\n        video_details['favoriteCount'] = statistics.get('favoriteCount', 0)\n\n        # Get top-level comments\n        comments_response = youtube.commentThreads().list(\n            part='snippet,replies',\n            videoId=video_id,\n            textFormat='plainText',\n            maxResults=100000  # Adjust as needed\n        ).execute()\n\n        for item in comments_response.get('items', []):\n            comment = item['snippet']['topLevelComment']['snippet']\n            comments_data.append({\n                'TotalVideoCommentsCount': len(comments_response.get('items', [])),\n                'videoId': video_id,\n                'Channel': video_details['channelTitle'],\n                'NumOfCommentlikes': comment.get('likeCount', 0),\n                'Comment': comment.get('textDisplay', ''),\n                'CommentedUserID': comment['authorChannelId']['value'],\n                'NumOfReplies': item['snippet'].get('totalReplyCount', 0),\n            })\n\n            # Get replies (if any)\n            if 'replies' in item:\n                for reply in item['replies']['comments']:\n                    reply_snippet = reply['snippet']\n                    comments_data.append({\n                        'TotalVideoCommentsCount': len(comments_response.get('items', [])),\n                        'videoId': video_id,\n                        'Channel': video_details['channelTitle'],\n                        'Reply': reply_snippet.get('textDisplay', ''),\n                        'RepliesLikes': reply_snippet.get('likeCount', 0),\n                        'RepliedUserID': reply_snippet['authorChannelId']['value'],\n                        'ToWhomTheyReplied': comment['authorChannelId']['value'],\n                    })\n        return video_details, comments_data\n    else:\n        return None, None\n\ndef save_to_csv(channel_name, video_details, comments_data):\n    \"\"\"Save video details and comments to a CSV file named after the channel.\"\"\"\n    filename = f'{channel_name}.csv'\n    file_exists = os.path.isfile(filename)\n    existing_video_ids = set()\n\n    if file_exists:\n        with open(filename, 'r', newline='', encoding='utf-8') as csvfile:\n            reader = csv.DictReader(csvfile)\n            existing_video_ids = {row['videoId'] for row in reader}\n\n    if video_details['videoId'] in existing_video_ids:\n        return\n\n    with open(filename, 'a', newline='', encoding='utf-8') as csvfile:\n        fieldnames = ['videoId', 'title', 'publishedAt', 'description', 'channelTitle', \n                      'tags', 'duration', 'viewCount', 'likeCount', 'favoriteCount',\n                      'TotalVideoCommentsCount', 'Channel', 'NumOfCommentlikes', \n                      'NumOfReplies', 'Comment', 'CommentedUserID', 'RepliedUserID', \n                      'Reply', 'RepliesLikes', 'ToWhomTheyReplied']\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n        if not file_exists:\n            writer.writeheader()\n\n        if video_details:\n            writer.writerow(video_details)\n        if comments_data:\n            writer.writerows(comments_data)\n\ndef process_channel(channel_id):\n    \"\"\"Process all videos in a channel and save details to CSV.\"\"\"\n    video_ids = get_channel_videos(channel_id)\n    for video_id in video_ids:\n        video_details, comments_data = get_video_details(video_id)\n        \n        if video_details and comments_data:\n            save_to_csv(video_details['channelTitle'], video_details, comments_data)\n        else:\n            print(f'Error retrieving video data for video ID {video_id}.')\n\nif __name__ == \"__main__\":\n    channel_id = 'UCUBNKEKMaWE-gkUZ2ptvyuQ'  # Replace with the actual channel ID\n    process_channel(channel_id)\n","metadata":{},"execution_count":null,"outputs":[]}]}